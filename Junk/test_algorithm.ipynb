{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from team_template.src.model_task_1_ import main as evaluate_model_1\n",
    "from team_template.src.models import Unet2\n",
    "from team_template.src.post_processing import MorphologicalOperations\n",
    "#from competition_toolkit.competition_toolkit.dataloader import create_dataloader\n",
    "from competition_toolkit.competition_toolkit.eval_functions import iou, biou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from yaml import load, Loader\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def get_paths_from_folder(folder: str) -> list:\n",
    "    allowed_filetypes = [\"jpg\", \"jpeg\", \"png\", \"tif\", \"tiff\"]\n",
    "\n",
    "    paths = []\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        filetype = file.split(\".\")[1]\n",
    "\n",
    "        if filetype not in allowed_filetypes:\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(folder, file)\n",
    "\n",
    "        paths.append(path)\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def load_image(imagepath: str, size: tuple) -> torch.tensor:\n",
    "    #imagepath = 'data\\\\validation\\\\images\\\\6259_564_0.tif'\n",
    "    image = cv.imread(imagepath, cv.IMREAD_COLOR)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image = cv.resize(image, size)\n",
    "\n",
    "    image = torch.tensor(image.astype(np.uint8)) / 255\n",
    "    image = torch.permute(image, (2, 0, 1))\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_label(labelpath: str, size: tuple) -> torch.tensor:\n",
    "    label = cv.imread(labelpath, cv.IMREAD_GRAYSCALE)\n",
    "    label[label == 255] = 1\n",
    "    label = cv.resize(label, size)\n",
    "\n",
    "    label = torch.tensor(label.astype(np.uint8)).long()\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "def download_dataset(data_type: str, task: int, get_dataset: bool = False):\n",
    "    if data_type == \"test\":\n",
    "        #paths = os.listdir('data/test/images')\n",
    "        #print(f'train {paths}')\n",
    "        paths = load_dataset(\"sjyhne/mapai_dataset\", split='task1_test', use_auth_token='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')\n",
    "    else:\n",
    "        paths = load_dataset(\"sjyhne/mapai_training_data\", split=data_type)\n",
    "        print(f'else: {paths}')\n",
    "\n",
    "    if get_dataset:\n",
    "        return paths\n",
    "\n",
    "    single_path = pathlib.Path(paths[0][\"image\"]).parent.parent.absolute()\n",
    "    return single_path\n",
    "\n",
    "class ImageAndLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 opts: dict,\n",
    "                 datatype: str = \"validation\"):\n",
    "\n",
    "        self.opts = opts\n",
    "\n",
    "        self.paths = download_dataset(data_type=datatype, task=opts[\"task\"], get_dataset=True)\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(\n",
    "            f\"Using number of images in {datatype}dataset: {int(self.paths.num_rows * self.opts['data_ratio'])}/{self.paths.num_rows}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.paths.num_rows * self.opts[\"data_ratio\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pathdict = self.paths[idx]\n",
    "\n",
    "        imagefilepath = pathdict[\"image\"]\n",
    "        labelfilepath = pathdict[\"mask\"]\n",
    "\n",
    "        assert imagefilepath.split(\"\\\\\")[-1] == labelfilepath.split(\"\\\\\")[\n",
    "            -1], f\"imagefilename and labelfilename does not match; {imagefilepath.split('/')[-1]} != {labelfilepath.split('/')[-1]}\"\n",
    "        filename = imagefilepath.split(\"/\")[-1]\n",
    "        #imagefilepath = os.path.abspath(imagefilepath)\n",
    "        imagefilepath = imagefilepath.replace('/', '\\\\')\n",
    "        labelfilepath = labelfilepath.replace('/', '\\\\')\n",
    "\n",
    "        imagefilepath = imagefilepath[6:]\n",
    "        labelfilepath = labelfilepath[6:]\n",
    "\n",
    "        image = load_image(imagefilepath, (self.opts[\"imagesize\"], self.opts[\"imagesize\"]))\n",
    "        label = load_label(labelfilepath, (self.opts[\"imagesize\"], self.opts[\"imagesize\"]))\n",
    "\n",
    "        assert image.shape[1:] == label.shape[\n",
    "                                  :2], f\"image and label shape not the same; {image.shape[1:]} != {label.shape[:2]}\"\n",
    "        return image, label, filename\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 opts: dict,\n",
    "                 datatype: str = \"test\"):\n",
    "        self.opts = opts\n",
    "\n",
    "        self.imagepaths = get_paths_from_folder(opts[datatype][\"imagefolder\"])\n",
    "\n",
    "        print(f\"Number of images in {datatype}dataset: {len(self)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imagefilepath = self.imagepaths[idx]\n",
    "\n",
    "        filename = imagefilepath.split(\"/\")[-1]\n",
    "\n",
    "        image = load_image(imagefilepath, (self.opts[\"imagesize\"], self.opts[\"imagesize\"]))\n",
    "\n",
    "        return image, filename\n",
    "\n",
    "\n",
    "def create_dataloader(opts: dict, datatype: str = \"test\") -> DataLoader:\n",
    "    dataset = ImageAndLabelDataset(opts, datatype)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=opts[f\"task{opts['task']}\"][\"batchsize\"], shuffle=opts[f\"task{opts['task']}\"][\"shuffle\"])\n",
    "\n",
    "    return dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1rMGoGKoKBBSz7C2THJFiz8L1CWRKf9_I\n",
      "From (redirected): https://drive.google.com/uc?id=1rMGoGKoKBBSz7C2THJFiz8L1CWRKf9_I&confirm=t&uuid=13d3db4e-a386-4161-a0bf-aea1bc515bb1\n",
      "To: C:\\Users\\hagtv\\Desktop\\Studies\\vår_2023\\ikt452\\IKT452-Project\\project\\ikt452-computer-vision-project\\pretrained_task1.pt\n",
      "100%|██████████| 31.1M/31.1M [00:06<00:00, 4.83MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Unet2(\n  (down1): DoubleConv(\n    (seq): Sequential(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n      (6): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (down2): DoubleConv(\n    (seq): Sequential(\n      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n      (6): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (down3): DoubleConv(\n    (seq): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n      (6): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (down4): DoubleConv(\n    (seq): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n      (6): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (down5): DoubleConv(\n    (seq): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU()\n      (6): Dropout(p=0.5, inplace=False)\n    )\n  )\n  (up4): Up(\n    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n    (conv1): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1))\n    (conv2): DoubleConv(\n      (seq): Sequential(\n        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU()\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU()\n        (6): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (relu): ReLU()\n    (batch_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (up3): Up(\n    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n    (conv1): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n    (conv2): DoubleConv(\n      (seq): Sequential(\n        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU()\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU()\n        (6): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (relu): ReLU()\n    (batch_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (up2): Up(\n    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n    (conv1): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1))\n    (conv2): DoubleConv(\n      (seq): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU()\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU()\n        (6): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (relu): ReLU()\n    (batch_normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (up1): Up(\n    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n    (conv1): Conv2d(64, 32, kernel_size=(2, 2), stride=(1, 1))\n    (conv2): DoubleConv(\n      (seq): Sequential(\n        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU()\n        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU()\n        (6): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (relu): ReLU()\n    (batch_normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (post1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (relu): ReLU()\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = 'run_21'\n",
    "config = f'team_template/src/runs/task_1/{run}/opts.yaml'\n",
    "with open(config, \"r\") as f:\n",
    "    opts = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "pt_share_link = \"https://drive.google.com/file/d/1rMGoGKoKBBSz7C2THJFiz8L1CWRKf9_I/view?usp=sharing\"\n",
    "pt_id = pt_share_link.split(\"/\")[-2]\n",
    "\n",
    "# Download trained model ready for inference\n",
    "url_to_drive = f\"https://drive.google.com/uc?id={pt_id}\"\n",
    "model_checkpoint = \"pretrained_task1.pt\"\n",
    "\n",
    "gdown.download(url_to_drive, model_checkpoint, quiet=False)\n",
    "\n",
    "model = Unet2() #torchvision.models.segmentation.fcn_resnet50(pretrained=False, num_classes=opts[\"num_classes\"])\n",
    "model.load_state_dict(torch.load(model_checkpoint))\n",
    "device = opts[\"device\"]\n",
    "model = model.to(device)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "morphological_operations = MorphologicalOperations(kernel_size=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/hagtv/.cache/huggingface/datasets/sjyhne___parquet/sjyhne--mapai_dataset-a29285241f23b7c3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using number of images in testdataset: 1368/1368\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002876D051A60>\n"
     ]
    }
   ],
   "source": [
    "datatype = 'test'\n",
    "opts['task1']['batchsize'] = 1\n",
    "dataloader = create_dataloader(opts, datatype=datatype)\n",
    "print(dataloader)\n",
    "\n",
    "iou_scores = np.zeros((len(dataloader)))\n",
    "biou_scores = np.zeros((len(dataloader)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/1368 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for idx, (image, label, filename) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Inference\",\n",
    "                                              leave=False):\n",
    "    # Split filename and extension\n",
    "    filename_base, file_extension = os.path.splitext(filename[0])\n",
    "\n",
    "    # Send image and label to device (eg., cuda)\n",
    "    image = image.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    # Perform model prediction\n",
    "    prediction = model(image)[\"out\"]\n",
    "    if opts[\"device\"] == \"cpu\":\n",
    "        prediction = torch.argmax(torch.softmax(prediction, dim=1), dim=1).squeeze().detach().numpy()\n",
    "    else:\n",
    "        prediction = torch.argmax(torch.softmax(prediction, dim=1), dim=1).squeeze().cpu().detach().numpy()\n",
    "    # Postprocess prediction\n",
    "\n",
    "    prediction = morphological_operations(prediction)\n",
    "        ##\n",
    "    if opts[\"device\"] == \"cpu\":\n",
    "        label = label.squeeze().detach().numpy()\n",
    "    else:\n",
    "        label = label.squeeze().cpu().detach().numpy()\n",
    "\n",
    "    prediction = np.uint8(prediction)\n",
    "    label = np.uint8(label)\n",
    "    assert prediction.shape == label.shape, f\"Prediction and label shape is not same, pls fix [{prediction.shape} - {label.shape}]\"\n",
    "\n",
    "    # Predict score\n",
    "    iou_score = iou(prediction, label)\n",
    "    biou_score = biou(label, prediction)\n",
    "\n",
    "    iou_scores[idx] = np.round(iou_score, 6)\n",
    "    biou_scores[idx] = np.round(biou_score, 6)\n",
    "\n",
    "    prediction_visual = np.copy(prediction)\n",
    "\n",
    "    for idx, value in enumerate(opts[\"classes\"]):\n",
    "        prediction_visual[prediction_visual == idx] = opts[\"class_to_color\"][value]\n",
    "\n",
    "    if opts[\"device\"] == \"cpu\":\n",
    "        image = image.squeeze().detach().numpy()[:3, :, :].transpose(1, 2, 0)\n",
    "    else:\n",
    "        image = image.squeeze().cpu().detach().numpy()[:3, :, :].transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"iou_score:\", np.round(iou_scores.mean(), 5), \"biou_score:\", np.round(biou_scores.mean(), 5))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}